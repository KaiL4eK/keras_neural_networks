{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No labels are provided. Train on all seen labels.\n",
      "{'sign': 852}\n",
      "{'sign': 476}\n",
      "\n",
      "Training on: \t['sign']\n",
      "\n",
      "Loading \"Darknet19\" model\n",
      "YoloLayer anchors: [8, 13, 13, 23, 25, 41] / max_grid: [14, 14]\n",
      "Laoding yolov2.h5\n",
      "Tensorboard dir: logs/TSD_YOLOv2_Darknet19_416x416-29\n",
      "Freezing 71 layers of 75\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 13.6654 - val_loss: 15.8007\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 9.2875 - val_loss: 14.9955\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 8.9319 - val_loss: 14.7719\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 8.5299 - val_loss: 14.8494\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 8.0909 - val_loss: 14.7327\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 7.9330 - val_loss: 15.0125\n",
      "Epoch 00006: early stopping\n",
      "Full training\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 35s 233ms/step - loss: 7.1362 - val_loss: 14.8920\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.89198, saving model to chk/TSD_YOLOv2_Darknet19_416x416_ep001-val_loss14.892-loss7.136.h5\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "\n",
      "Epoch 00000: mAP improved from 0 to 0, saving model to chk/TSD_YOLOv2_Darknet19_416x416_ep001-val_loss14.892-best_mAP0.000.h5\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 27s 179ms/step - loss: 6.7827 - val_loss: 14.9406\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 14.89198\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 5.9653 - val_loss: 14.7476\n",
      "\n",
      "Epoch 00003: val_loss improved from 14.89198 to 14.74760, saving model to chk/TSD_YOLOv2_Darknet19_416x416_ep003-val_loss14.748-loss5.965.h5\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "\n",
      "Epoch 00002: mAP improved from 0 to 0, saving model to chk/TSD_YOLOv2_Darknet19_416x416_ep003-val_loss14.748-best_mAP0.000.h5\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 27s 181ms/step - loss: 5.9132 - val_loss: 14.8308\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 27s 183ms/step - loss: 5.8820 - val_loss: 15.2134\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 5.3709 - val_loss: 15.1271\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 4.8670 - val_loss: 15.1314\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 5.2027 - val_loss: 15.1346\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 4.6489 - val_loss: 15.0418\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 4.7423 - val_loss: 15.1905\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 4.3689 - val_loss: 14.9937\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 4.3586 - val_loss: 14.9946\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 4.2005 - val_loss: 14.9346\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0001\n",
      "mAP: 0.0001\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 4.0222 - val_loss: 15.0265\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 4.1657 - val_loss: 15.1234\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 3.6915 - val_loss: 15.0728\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 4.0580 - val_loss: 15.0655\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 30s 197ms/step - loss: 3.9698 - val_loss: 15.3890\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 4.0693 - val_loss: 15.2356\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 3.5161 - val_loss: 15.1440\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0001\n",
      "mAP: 0.0001\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 4.0473 - val_loss: 15.2700\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 3.7254 - val_loss: 15.3119\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 3.7823 - val_loss: 15.1939\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 3.5262 - val_loss: 14.8749\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 30s 198ms/step - loss: 3.4516 - val_loss: 15.3820\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0001\n",
      "mAP: 0.0001\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 3.4931 - val_loss: 14.9549\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 3.5967 - val_loss: 15.1537\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 3.3380 - val_loss: 15.0905\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 3.6429 - val_loss: 15.1561\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 3.1755 - val_loss: 15.0664\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 27s 178ms/step - loss: 3.6213 - val_loss: 15.1234\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 3.1842 - val_loss: 15.0821\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 27s 183ms/step - loss: 3.6315 - val_loss: 15.1959\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 3.2235 - val_loss: 15.5290\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 3.1230 - val_loss: 15.2439\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 30s 199ms/step - loss: 3.2030 - val_loss: 15.2911\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0001\n",
      "mAP: 0.0001\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 3.0350 - val_loss: 15.2912\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0001\n",
      "mAP: 0.0001\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 29s 190ms/step - loss: 3.4159 - val_loss: 15.0605\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 30s 199ms/step - loss: 2.7781 - val_loss: 15.0017\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 3.1235 - val_loss: 14.9812\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 3.2825 - val_loss: 15.0884\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 2.9999 - val_loss: 15.0507\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 3.1661 - val_loss: 15.2081\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 2.8826 - val_loss: 14.9965\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 3.0418 - val_loss: 15.0145\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 3.3066 - val_loss: 15.2653\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 3.0249 - val_loss: 15.1246\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 2.8505 - val_loss: 15.1300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 2.7394 - val_loss: 15.1920\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 14.74760\n",
      "\n",
      "\n",
      "0 0.0000\n",
      "mAP: 0.0000\n",
      "mAP did not improve from 0.0.\n",
      "Epoch 50/300\n",
      " 12/150 [=>............................] - ETA: 20s - loss: 2.8291"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from yolo import create_model, dummy_loss\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize, evaluate, makedirs, init_session\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.layer_utils import print_summary\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import core\n",
    "from _common import utils\n",
    "from _common.callbacks import CustomModelCheckpoint, CustomTensorBoard, MAP_evaluation\n",
    "from _common.voc import parse_voc_annotation, split_by_objects, replace_all_labels_2_one\n",
    "\n",
    "def create_training_instances(\n",
    "        train_annot_folder,\n",
    "        train_image_folder,\n",
    "        train_cache,\n",
    "        valid_annot_folder,\n",
    "        valid_image_folder,\n",
    "        valid_cache,\n",
    "        labels,\n",
    "):\n",
    "    # parse annotations of the training set\n",
    "    train_ints, train_labels = parse_voc_annotation(train_annot_folder, train_image_folder, train_cache, labels)\n",
    "\n",
    "    # parse annotations of the validation set, if any, otherwise split the training set\n",
    "    if valid_annot_folder:\n",
    "        valid_ints, valid_labels = parse_voc_annotation(valid_annot_folder, valid_image_folder, valid_cache, labels)\n",
    "    else:\n",
    "        print(\"valid_annot_folder not exists. Spliting the trainining set.\")\n",
    "\n",
    "        train_ints, valid_ints = split_by_objects(train_ints, train_labels, 0.2)\n",
    "\n",
    "    # Hack - replace full dataset to only one class\n",
    "    train_ints, train_labels = replace_all_labels_2_one( train_ints, 'sign' )\n",
    "    valid_ints, valid_labels = replace_all_labels_2_one( valid_ints, 'sign' )\n",
    "        \n",
    "        \n",
    "    # compare the seen labels with the given labels in config.json\n",
    "    if len(labels) > 0:\n",
    "        overlap_labels = set(labels).intersection(set(train_labels.keys()))\n",
    "\n",
    "        print('Seen labels: \\t' + str(train_labels) + '\\n')\n",
    "        print('Given labels: \\t' + str(labels))\n",
    "\n",
    "        # return None, None, None if some given label is not in the dataset\n",
    "        if len(overlap_labels) < len(labels):\n",
    "            print('Some labels have no annotations! Please revise the list of labels in the config.json.')\n",
    "            return None, None, None\n",
    "    else:\n",
    "        print('No labels are provided. Train on all seen labels.')\n",
    "        print(train_labels)\n",
    "        print(valid_labels)\n",
    "        labels = train_labels.keys()\n",
    "\n",
    "    max_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
    "\n",
    "    return train_ints, valid_ints, sorted(labels), max_box_per_image\n",
    "\n",
    "\n",
    "def train(config, initial_weights):\n",
    "\n",
    "    init_session(1.0)\n",
    "\n",
    "    if config['train']['cache_name']:\n",
    "        makedirs(os.path.dirname(config['train']['cache_name']))\n",
    "\n",
    "    ###############################\n",
    "    #   Parse the annotations\n",
    "    ###############################\n",
    "    train_ints, valid_ints, labels, max_box_per_image = create_training_instances(\n",
    "        config['train']['train_annot_folder'],\n",
    "        config['train']['train_image_folder'],\n",
    "        config['train']['cache_name'],\n",
    "        config['valid']['valid_annot_folder'],\n",
    "        config['valid']['valid_image_folder'],\n",
    "        config['valid']['cache_name'],\n",
    "        config['model']['labels']\n",
    "    )\n",
    "    print('\\nTraining on: \\t' + str(labels) + '\\n')\n",
    "\n",
    "    ###############################\n",
    "    #   Create the generators\n",
    "    ###############################\n",
    "    train_generator = BatchGenerator(\n",
    "        instances=train_ints,\n",
    "        anchors=config['model']['anchors'],\n",
    "        labels=labels,\n",
    "        downsample=32,  # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "        max_box_per_image=max_box_per_image,\n",
    "        batch_size=config['train']['batch_size'],\n",
    "        min_net_size=config['model']['min_input_size'],\n",
    "        max_net_size=config['model']['max_input_size'],\n",
    "        shuffle=True,\n",
    "        jitter=0.1,\n",
    "        norm=normalize\n",
    "    )\n",
    "\n",
    "    valid_generator = BatchGenerator(\n",
    "        instances=valid_ints,\n",
    "        anchors=config['model']['anchors'],\n",
    "        labels=labels,\n",
    "        downsample=32,  # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "        max_box_per_image=max_box_per_image,\n",
    "        batch_size=config['train']['batch_size'],\n",
    "        norm=normalize,\n",
    "        infer_sz=config['model']['infer_shape']\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    #   Create the model\n",
    "    ###############################\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
    "    multi_gpu = len(config['train']['gpus'].split(','))\n",
    "\n",
    "    freezing = True\n",
    "    config['train']['warmup_epochs'] = 0\n",
    "\n",
    "    warmup_batches = config['train']['warmup_epochs'] * (config['train']['train_times'] * len(train_generator))\n",
    "\n",
    "    train_model, infer_model, _, freeze_num = create_model(\n",
    "        nb_class=len(labels),\n",
    "        anchors=config['model']['anchors'],\n",
    "        max_box_per_image=max_box_per_image,\n",
    "        max_input_size=config['model']['max_input_size'],\n",
    "        batch_size=config['train']['batch_size'],\n",
    "        warmup_batches=warmup_batches,\n",
    "        ignore_thresh=config['train']['ignore_thresh'],\n",
    "        multi_gpu=multi_gpu,\n",
    "        grid_scales=config['train']['grid_scales'],\n",
    "        obj_scale=config['train']['obj_scale'],\n",
    "        noobj_scale=config['train']['noobj_scale'],\n",
    "        xywh_scale=config['train']['xywh_scale'],\n",
    "        class_scale=config['train']['class_scale'],\n",
    "        base=config['model']['base']\n",
    "    )\n",
    "\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "    model_render_file = 'images/{}.png'.format(config['model']['base'])\n",
    "    if not os.path.isdir(os.path.dirname(model_render_file)):\n",
    "        os.makedirs(os.path.dirname(model_render_file))\n",
    "    plot_model(infer_model, to_file=model_render_file, show_shapes=True)\n",
    "#     print_summary(infer_model)\n",
    "\n",
    "    # load the pretrained weight if exists, otherwise load the backend weight only\n",
    "    if initial_weights and os.path.exists(initial_weights):\n",
    "        print(\"\\nLoading pretrained weights {}\".format(initial_weights))\n",
    "        train_model.load_weights(initial_weights, by_name=True, skip_mismatch=True)\n",
    "\n",
    "        freezing = False\n",
    "\n",
    "    ###############################\n",
    "    #   Kick off the training\n",
    "    ###############################\n",
    "    tensorboard_logdir = utils.get_tensorboard_name(config)\n",
    "    checkpoint_name = utils.get_checkpoint_name(config)\n",
    "    mAP_checkpoint_name = utils.get_mAP_checkpoint_name(config)\n",
    "    utils.makedirs(tensorboard_logdir)\n",
    "    utils.makedirs_4_file(checkpoint_name)\n",
    "    utils.makedirs_4_file(mAP_checkpoint_name)\n",
    "\n",
    "    print('Tensorboard dir: {}'.format(tensorboard_logdir))\n",
    "\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.1,\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    callbacks = [early_stop]\n",
    "\n",
    "    if freezing and freeze_num > 0:\n",
    "        print('Freezing %d layers of %d' % (freeze_num, len(infer_model.layers)))\n",
    "        for l in range(freeze_num):\n",
    "            infer_model.layers[l].trainable = False\n",
    "\n",
    "        # optimizer = Adam(lr=1e-3, clipnorm=0.1)\n",
    "        optimizer = Adam()\n",
    "        train_model.compile(loss=dummy_loss, optimizer=optimizer)\n",
    "        train_model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            steps_per_epoch=len(train_generator) * config['train']['train_times'],\n",
    "\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=len(valid_generator) * config['valid']['valid_times'],\n",
    "\n",
    "            epochs=config['train']['nb_epochs'] + config['train']['warmup_epochs'],\n",
    "            verbose=2 if config['train']['debug'] else 1,\n",
    "            callbacks=callbacks,\n",
    "            workers=8,\n",
    "            max_queue_size=100\n",
    "        )\n",
    "\n",
    "    # make a GPU version of infer_model for evaluation\n",
    "    # if multi_gpu > 1:\n",
    "    #     infer_model = load_model(config['train']['saved_weights_name'])\n",
    "\n",
    "    print('Full training')\n",
    "\n",
    "    for layer in infer_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    checkpoint_vloss = CustomModelCheckpoint(\n",
    "        model_to_save=infer_model,\n",
    "        filepath=checkpoint_name,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        period=1\n",
    "    )\n",
    "\n",
    "    reduce_on_plateau = ReduceLROnPlateau(\n",
    "        monitor='loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        min_delta=0.01,\n",
    "        cooldown=0,\n",
    "        min_lr=0\n",
    "    )\n",
    "\n",
    "    tensorboard_cb = TensorBoard(log_dir=tensorboard_logdir,\n",
    "                                 histogram_freq=0,\n",
    "                                 write_graph=True,\n",
    "                                 write_images=False)\n",
    "\n",
    "    map_evaluator_cb = MAP_evaluation(infer_model=infer_model,\n",
    "                                      generator=valid_generator,\n",
    "                                      save_best=True,\n",
    "                                      save_name=mAP_checkpoint_name,\n",
    "                                      tensorboard=tensorboard_cb,\n",
    "                                      iou_threshold=0.5,\n",
    "                                      score_threshold=0.5,\n",
    "                                      infer_sz=config['model']['infer_shape'],\n",
    "                                      evaluate=evaluate)\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=20,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    from keras.optimizers import SGD\n",
    "\n",
    "    callbacks = [checkpoint_vloss, tensorboard_cb, map_evaluator_cb]\n",
    "\n",
    "    optimizer = Adam(lr=config['train']['learning_rate'], clipnorm=0.001)\n",
    "    # optimizer = SGD(lr=config['train']['learning_rate'], clipnorm=0.001)\n",
    "\n",
    "    train_model.compile(loss=dummy_loss, optimizer=optimizer)\n",
    "    train_model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=len(train_generator) * config['train']['train_times'],\n",
    "\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=len(valid_generator) * config['valid']['valid_times'],\n",
    "\n",
    "        epochs=config['train']['nb_epochs'] + config['train']['warmup_epochs'],\n",
    "        verbose=2 if config['train']['debug'] else 1,\n",
    "        callbacks=callbacks,\n",
    "        workers=8,\n",
    "        max_queue_size=100\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    #   Run the evaluation\n",
    "    ###############################\n",
    "    # compute mAP for all the classes\n",
    "    average_precisions = evaluate(model=infer_model,\n",
    "                                  generator=valid_generator,\n",
    "                                  iou_threshold=0.5,\n",
    "                                  net_h=config['model']['infer_shape'][0],\n",
    "                                  net_w=config['model']['infer_shape'][1] )\n",
    "\n",
    "    # print the score\n",
    "    for label, average_precision in average_precisions.items():\n",
    "        print(labels[label] + ': {:.4f}'.format(average_precision))\n",
    "    print('Last mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config_path = 'cfgs/signs_v2.json'\n",
    "    initial_weights = None\n",
    "\n",
    "    with open(config_path) as config_buffer:\n",
    "        config = json.loads(config_buffer.read())\n",
    "\n",
    "    train(config, initial_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
